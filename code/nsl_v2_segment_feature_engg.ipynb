{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53b9182",
   "metadata": {},
   "source": [
    "### Load the required libraries and functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b278214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import re\n",
    "import joblib\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "project_path = '/Users/naresh/Downloads/DS/growth/nsl_v2/nsl_v2_final/'\n",
    "sys.path.insert(0, project_path+'config')\n",
    "from config import SQLQuery\n",
    "\n",
    "random.seed(3)\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "color_map = {1: '#00cc96', 0: '#636efa'}\n",
    "# Avoid warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e21a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_test = pd.read_pickle(project_path+'data/nsl_train_test_flag_2023-05-30.pkl')\n",
    "df_segment = pd.read_pickle(project_path+'data/segment_raw_dataset_2023-05-30.pkl')\n",
    "\n",
    "df = pd.merge(df_segment,df_train_test[['application_id','train_flag','test_flag']], on='application_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e499ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visits per page for all the common pages - done\n",
    "# no.of unique page visits till 13th question - done\n",
    "# time spent per unique page till 13th question - difficult to build logic for this data\n",
    "# total time spent till 13th question - not explored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439dc64",
   "metadata": {},
   "source": [
    "### Final modules for the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0821855b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def segment_features_1(df:pd.DataFrame, cols_list:list, app_level_df:pd.DataFrame, training:bool=True):\n",
    "    \"\"\" \n",
    "        df : segment raw data\n",
    "        cols_list: columns list on which the operations are performed\n",
    "        app_level_df: application level data\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    new_cols = []\n",
    "    for col in cols_list:\n",
    "        tmp = df[['application_id',col]].drop_duplicates(subset=['application_id',col], keep='first')\n",
    "        tmp2 = pd.DataFrame(tmp.application_id.value_counts()).reset_index()\n",
    "        col = col+'_count'\n",
    "        tmp2.rename(columns={'application_id':col, 'index':'application_id'}, inplace=True)\n",
    "    \n",
    "        # Merging with app level df\n",
    "        app_level_df = pd.merge(app_level_df, tmp2, on='application_id', how='left')\n",
    "        new_cols.append(col)\n",
    "        \n",
    "    if training:\n",
    "        df_impute_segment = app_level_df[new_cols].median()\n",
    "        df_impute_segment = pd.DataFrame(df_impute_segment, columns=['impute_value']).reset_index().rename(columns={'index':'feature'})\n",
    "        df_impute_segment.to_pickle(project_path+'models/df_impute_segment.pkl') # Save the impute values as df\n",
    "\n",
    "    else:\n",
    "        df_impute_segment = pd.read_pickle(project_path+'models/df_impute_segment.pkl') # Load the impute values as df\n",
    "\n",
    "    # screen height and width features\n",
    "    tmp2 = pd.DataFrame()\n",
    "    tmp2 = pd.concat([tmp2, df[['application_id','screen_height','screen_width']]])\n",
    "    tmp2.drop_duplicates(subset=['application_id','screen_height','screen_width'],keep='first', inplace=True)\n",
    "\n",
    "    new_cols2 = []\n",
    "    list_value_type = ['max','min','mean','median']\n",
    "    for value_type in list_value_type:\n",
    "        colw = 'screen_width'\n",
    "        tmp = pd.DataFrame(tmp2.groupby(['application_id'])[colw].agg([value_type]))\n",
    "        tmp[value_type] = tmp[value_type].astype('float')\n",
    "        tmp.rename(columns={value_type:colw+'_'+value_type}, inplace=True) \n",
    "        app_level_df = pd.merge(app_level_df, tmp, on='application_id', how='left')\n",
    "        \n",
    "        new_cols2.append(colw+'_'+value_type)\n",
    "\n",
    "        colh = 'screen_height'\n",
    "        tmp = pd.DataFrame(tmp2.groupby(['application_id'])[colh].agg([value_type]))\n",
    "        tmp[value_type] = tmp[value_type].astype('float')\n",
    "        tmp.rename(columns={value_type:colh+'_'+value_type}, inplace=True) \n",
    "        app_level_df = pd.merge(app_level_df, tmp, on='application_id', how='left')\n",
    "        \n",
    "        new_cols2.append(colh+'_'+value_type)\n",
    "        \n",
    "    if training:\n",
    "        df_impute_segment2 = app_level_df[new_cols2].median()\n",
    "        df_impute_segment2 = pd.DataFrame(df_impute_segment2, columns=['impute_value']).reset_index().rename(columns={'index':'feature'})\n",
    "        df_impute_segment2.to_pickle(project_path+'models/df_impute_segment2.pkl') # Save the impute values as df\n",
    "\n",
    "    else:\n",
    "        df_impute_segment2 = pd.read_pickle(project_path+'models/df_impute_segment2.pkl') # Load the impute values as df\n",
    "\n",
    "    return app_level_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff89015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_features_2(df:pd.DataFrame, app_level_df:pd.DataFrame, training:bool=True):\n",
    "    \"\"\" \n",
    "        df : segment raw data\n",
    "        cols_list: columns list on which the operations are performed\n",
    "        app_level_df: application level data\n",
    "        \n",
    "    \"\"\"\n",
    "    # Cleaning the list of owner_ids\n",
    "    def clean_string(x):\n",
    "        if x != None:\n",
    "            x = str(x)\n",
    "            x = [val.strip(\"\"\"'|[| |\"|,|]\"\"\") for val in x.split('/') if not val.strip(\"\"\"'|[| |\"|,|]\"\"\") in ['',None] and len(val.strip(\"\"\"'|[| |\"|,|]\"\"\"))<36]\n",
    "        return '/'.join(x)\n",
    "\n",
    "    df['context_page_path_clean'] = df['context_page_path'].apply(clean_string)\n",
    "    # One-hot encoding the unique page paths\n",
    "    col = 'context_page_path_clean'\n",
    "    tmp = df[col].str.get_dummies()\n",
    "    tmp['application_id'] = df.application_id\n",
    "    # Common pages that every applicant must visit\n",
    "    common_pages = ['verify-email-otp','welcome','app/applicant/personal-info','app/applicant/phone'\n",
    "    ,'app/applicant/otp-verify','app/applicant/address','app/applicant/dob-ssn','app/business/business-type'\n",
    "    ,'app/business/address','app/business/other-info','app/business-questions/about-business'\n",
    "    ,'app/business-questions/incoming']\n",
    "\n",
    "    # no.of visits per page\n",
    "    tmp2 = tmp[common_pages+['application_id']].groupby(['application_id']).sum()\n",
    "    tmp2.reset_index(drop=False, inplace=True)\n",
    "    tmp2 = pd.merge(app_level_df, tmp2, on='application_id', how='left')\n",
    "    \n",
    "    # no.of unique pages per user\n",
    "    tmp3 = tmp.groupby(['application_id']).sum()\n",
    "    tmp3.reset_index(drop=False, inplace=True)\n",
    "    tmp3 = pd.merge(tmp3, app_level_df[['application_id']], on='application_id', how='left')\n",
    "    drop_cols = ['404','app/applicant','app/business','application-denied','forgot-password','signup','status','undefined']\n",
    "    drop_cols = [col for col in tmp3.columns.to_list() if col in drop_cols]\n",
    "    tmp3 = tmp3.drop(columns=drop_cols)\n",
    "    tmp3 = tmp3.dropna(subset=['application_id'])\n",
    "    \n",
    "    tmp4 = pd.DataFrame()\n",
    "    tmp4['application_id'] = tmp3.application_id\n",
    "    cols = tmp3.drop(columns=['application_id']).columns.to_list()\n",
    "    tmp4[cols] = pd.DataFrame(np.where(tmp3[cols]>=1, 1, 0))\n",
    "    tmp4 = tmp4.set_index('application_id')\n",
    "    tmp4 = pd.DataFrame(tmp4.sum(axis=1), columns=['page_count'])\n",
    "    tmp2 = pd.merge(tmp2,tmp4,on='application_id',how='left')\n",
    "\n",
    "    if training:\n",
    "        df_impute_segment3 = tmp2[common_pages+['page_count']].median()\n",
    "        df_impute_segment3 = pd.DataFrame(df_impute_segment3, columns=['impute_value']).reset_index().rename(columns={'index':'feature'})\n",
    "        df_impute_segment3.to_pickle(project_path+'models/df_impute_segment3.pkl') # Save the impute values as df\n",
    "\n",
    "    else:\n",
    "        df_impute_segment3 = pd.read_pickle(project_path+'models/df_impute_segment3.pkl') # Load the impute values as df\n",
    "\n",
    "    return tmp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f473df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_features_3(app_level_df:pd.DataFrame):\n",
    "    \"\"\" \n",
    "        df : segment raw data\n",
    "        cols_list: columns list on which the operations are performed\n",
    "        app_level_df: application level data\n",
    "        \n",
    "    \"\"\"\n",
    "    impute1 = pd.read_pickle(project_path+'models/df_impute_segment.pkl')\n",
    "    impute2 = pd.read_pickle(project_path+'models/df_impute_segment2.pkl')\n",
    "    impute3 = pd.read_pickle(project_path+'models/df_impute_segment3.pkl')\n",
    "    \n",
    "    ############# PART-1 #############\n",
    "    # Function to fill nulls with median values\n",
    "    def fill_null_values(df_impute:pd.DataFrame, data_df:pd.DataFrame,):\n",
    "        df_dict = dict(df_impute.values)\n",
    "        impute_cols = df_impute['feature'].to_list()\n",
    "        for col in data_df.columns.to_list():\n",
    "            if col in impute_cols:\n",
    "                data_df[col] = data_df[col].fillna(df_dict[col])\n",
    "                impute_cols.remove(col)\n",
    "        return data_df\n",
    "\n",
    "    # Filling nulls with median\n",
    "    app_level_df = fill_null_values(impute1, app_level_df)\n",
    "    app_level_df['sh_sw_ratio_count'] = app_level_df['screen_height_count']/app_level_df['screen_width_count']\n",
    "    app_level_df['sh_sw_ratio_count'] = app_level_df['sh_sw_ratio_count'].astype('float')\n",
    "    \n",
    "    cols_list_1 = impute1.feature.to_list()\n",
    "    # Feature Engg\n",
    "    for col in cols_list_1:\n",
    "        app_level_df[col] = np.where(app_level_df[col]==1,1,0)\n",
    "        \n",
    "\n",
    "    ############# PART-2 #############\n",
    "    # Filling nulls with median\n",
    "    app_level_df = fill_null_values(impute2, app_level_df)\n",
    "\n",
    "    # Function to fill zero screen width and height with median values\n",
    "    def fill_zero_values(df_impute:pd.DataFrame, data_df:pd.DataFrame,):\n",
    "        df_dict = dict(df_impute.values)\n",
    "        impute_cols = df_impute['feature'].to_list()\n",
    "        for col in data_df.columns.to_list():\n",
    "            if col in impute_cols:\n",
    "                data_df[col] = np.where(data_df[col]==0, df_dict[col], data_df[col])\n",
    "                impute_cols.remove(col)\n",
    "        return data_df\n",
    "    \n",
    "    # Filling zeros with median\n",
    "    app_level_df = fill_zero_values(impute2, app_level_df)\n",
    "    # Creating Ratios\n",
    "    list_value_type = ['max','min','mean','median']\n",
    "    for value_type in list_value_type:\n",
    "        colh = 'screen_height'\n",
    "        colw = 'screen_width'\n",
    "        app_level_df['sh_sw_ratio_'+value_type] = app_level_df[colh+'_'+value_type]/app_level_df[colw+'_'+value_type]\n",
    "\n",
    "    \n",
    "    ############# PART-3 #############\n",
    "    cols_list_3 = impute3.feature.to_list()\n",
    "    app_level_df = fill_null_values(impute3, app_level_df)\n",
    "    \n",
    "    return app_level_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad94228",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1087b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[df['train_flag'] == 1].reset_index(drop=True)\n",
    "# Filter only the existing applications in segment data\n",
    "x_train = x_train[~x_train.received_at.isnull()]\n",
    "x_train.reset_index(drop=True, inplace=True)\n",
    "x_train = x_train.sort_values(by=['application_id','received_at'])\n",
    "\n",
    "\n",
    "# Change data type\n",
    "cols = ['application_id','user_id','owner_id','anonymous_id','context_page_path','timezone']\n",
    "x_train[cols] = x_train[cols].astype('string')\n",
    "x_train[['screen_width','screen_height']] = x_train[['screen_width','screen_height']].astype('int')\n",
    "\n",
    "for col in x_train.columns:\n",
    "    if col != 'user_id':\n",
    "        idx = x_train.index[x_train[col].isnull()].tolist()\n",
    "        idx.extend(x_train.index[x_train[col].isna()].tolist())\n",
    "        idx.extend(x_train.index[x_train[col] == ''].tolist())\n",
    "        idx.extend(x_train.index[x_train[col] == '[]'].tolist())\n",
    "        idx = list(set(idx))\n",
    "        x_train.loc[idx, col] = None    \n",
    "\n",
    "cols_list = ['timezone','user_id','owner_id','anonymous_id','context_ip','screen_width','screen_height']\n",
    "# Creating df with all apps\n",
    "app_level_data = pd.DataFrame()\n",
    "app_level_data['application_id'] = x_train.application_id.unique()\n",
    "\n",
    "app_level_data = segment_features_1(df=x_train, cols_list=cols_list, app_level_df=app_level_data, training=True)\n",
    "app_level_data = segment_features_2(df=x_train, app_level_df=app_level_data, training=True)\n",
    "\n",
    "\n",
    "df_tmp = pd.merge(df_train_test[['application_id', 'train_flag', 'test_flag','ns_flag']], app_level_data,\n",
    "              on='application_id', how='left')\n",
    "x_train = df_tmp[df_tmp['train_flag'] == 1].reset_index(drop=True)\n",
    "y_train = x_train['ns_flag']\n",
    "app_level_data_train = segment_features_3(app_level_df=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c19b81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_cols = app_level_data_train.drop(columns=['application_id']).columns.to_list()\n",
    "\n",
    "# hue_col = 'ns_flag'\n",
    "\n",
    "# f, axes = plt.subplots(len(num_cols),2, figsize=(8, 100), sharex=False)\n",
    "# for i, col in enumerate(num_cols):\n",
    "#     sns.violinplot(y=col, x=hue_col, orient='v', data=app_level_data_train, ax=axes[i,0])\n",
    "    \n",
    "#     # Capping upper and lower limits using IQR whiskers\n",
    "#     upper_limit = float(app_level_data_train[col].quantile([0.75]).values + 1.5*(app_level_data_train[col].quantile([0.75]).values - app_level_data_train[col].quantile([0.25]).values))\n",
    "#     lower_limit = float(app_level_data_train[col].quantile([0.25]).values - 1.5*(app_level_data_train[col].quantile([0.75]).values - app_level_data_train[col].quantile([0.25]).values))\n",
    "#     df_tmp = app_level_data_train[(app_level_data_train[col]<=upper_limit) & (app_level_data_train[col]>=lower_limit)].reset_index(drop=True)\n",
    "    \n",
    "#     sns.violinplot(y=col, x=hue_col, orient='v', data=df_tmp, ax=axes[i,1])\n",
    "    \n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68e8533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87292, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_level_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e683562c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87292 entries, 0 to 87291\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   application_id                         87292 non-null  object \n",
      " 1   train_flag                             87292 non-null  float64\n",
      " 2   test_flag                              87292 non-null  float64\n",
      " 3   ns_flag                                87292 non-null  int64  \n",
      " 4   timezone_count                         87292 non-null  int64  \n",
      " 5   user_id_count                          87292 non-null  int64  \n",
      " 6   owner_id_count                         87292 non-null  int64  \n",
      " 7   anonymous_id_count                     87292 non-null  int64  \n",
      " 8   context_ip_count                       87292 non-null  int64  \n",
      " 9   screen_width_count                     87292 non-null  int64  \n",
      " 10  screen_height_count                    87292 non-null  int64  \n",
      " 11  screen_width_max                       87292 non-null  float64\n",
      " 12  screen_height_max                      87292 non-null  float64\n",
      " 13  screen_width_min                       87292 non-null  float64\n",
      " 14  screen_height_min                      87292 non-null  float64\n",
      " 15  screen_width_mean                      87292 non-null  float64\n",
      " 16  screen_height_mean                     87292 non-null  float64\n",
      " 17  screen_width_median                    87292 non-null  float64\n",
      " 18  screen_height_median                   87292 non-null  float64\n",
      " 19  verify-email-otp                       87292 non-null  float64\n",
      " 20  welcome                                87292 non-null  float64\n",
      " 21  app/applicant/personal-info            87292 non-null  float64\n",
      " 22  app/applicant/phone                    87292 non-null  float64\n",
      " 23  app/applicant/otp-verify               87292 non-null  float64\n",
      " 24  app/applicant/address                  87292 non-null  float64\n",
      " 25  app/applicant/dob-ssn                  87292 non-null  float64\n",
      " 26  app/business/business-type             87292 non-null  float64\n",
      " 27  app/business/address                   87292 non-null  float64\n",
      " 28  app/business/other-info                87292 non-null  float64\n",
      " 29  app/business-questions/about-business  87292 non-null  float64\n",
      " 30  app/business-questions/incoming        87292 non-null  float64\n",
      " 31  page_count                             87292 non-null  float64\n",
      " 32  sh_sw_ratio_count                      87292 non-null  float64\n",
      " 33  sh_sw_ratio_max                        87292 non-null  float64\n",
      " 34  sh_sw_ratio_min                        87292 non-null  float64\n",
      " 35  sh_sw_ratio_mean                       87292 non-null  float64\n",
      " 36  sh_sw_ratio_median                     87292 non-null  float64\n",
      "dtypes: float64(28), int64(8), object(1)\n",
      "memory usage: 24.6+ MB\n"
     ]
    }
   ],
   "source": [
    "app_level_data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ddcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_level_data_train.to_pickle(project_path+'data/segment_processed_data_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326292a",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65911de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df[df['test_flag'] == 1].reset_index(drop=True)\n",
    "\n",
    "# Filter only the existing applications in segment data\n",
    "x_test = x_test[~x_test.received_at.isnull()]\n",
    "x_test.reset_index(drop=True, inplace=True)\n",
    "x_test = x_test.sort_values(by=['application_id','received_at'])\n",
    "\n",
    "\n",
    "# Change data type\n",
    "cols = ['application_id','user_id','owner_id','anonymous_id','context_page_path','timezone']\n",
    "x_test[cols] = x_test[cols].astype('string')\n",
    "x_test[['screen_width','screen_height']] = x_test[['screen_width','screen_height']].astype('int')\n",
    "\n",
    "for col in x_test.columns:\n",
    "    if col != 'user_id':\n",
    "        idx = x_test.index[x_test[col].isnull()].tolist()\n",
    "        idx.extend(x_test.index[x_test[col].isna()].tolist())\n",
    "        idx.extend(x_test.index[x_test[col] == ''].tolist())\n",
    "        idx.extend(x_test.index[x_test[col] == '[]'].tolist())\n",
    "        idx = list(set(idx))\n",
    "        x_test.loc[idx, col] = None\n",
    "\n",
    "cols_list = ['timezone','user_id','owner_id','anonymous_id','context_ip','screen_width','screen_height']\n",
    "# Creating df with all apps\n",
    "app_level_data = pd.DataFrame()\n",
    "app_level_data['application_id'] = x_test.application_id.unique()\n",
    "\n",
    "app_level_data = segment_features_1(df=x_test, cols_list=cols_list, app_level_df=app_level_data, training=False)\n",
    "app_level_data = segment_features_2(df=x_test, app_level_df=app_level_data, training=False)\n",
    "\n",
    "\n",
    "df_tmp = pd.merge(df_train_test[['application_id', 'train_flag', 'test_flag','ns_flag']], app_level_data,\n",
    "              on='application_id', how='left')\n",
    "x_test = df_tmp[df_tmp['test_flag'] == 1].reset_index(drop=True)\n",
    "y_test = x_test['ns_flag']\n",
    "app_level_data_test = segment_features_3(app_level_df=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d065e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37411, 37)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_level_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c96fa01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37411 entries, 0 to 37410\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   application_id                         37411 non-null  object \n",
      " 1   train_flag                             37411 non-null  float64\n",
      " 2   test_flag                              37411 non-null  float64\n",
      " 3   ns_flag                                37411 non-null  int64  \n",
      " 4   timezone_count                         37411 non-null  int64  \n",
      " 5   user_id_count                          37411 non-null  int64  \n",
      " 6   owner_id_count                         37411 non-null  int64  \n",
      " 7   anonymous_id_count                     37411 non-null  int64  \n",
      " 8   context_ip_count                       37411 non-null  int64  \n",
      " 9   screen_width_count                     37411 non-null  int64  \n",
      " 10  screen_height_count                    37411 non-null  int64  \n",
      " 11  screen_width_max                       37411 non-null  float64\n",
      " 12  screen_height_max                      37411 non-null  float64\n",
      " 13  screen_width_min                       37411 non-null  float64\n",
      " 14  screen_height_min                      37411 non-null  float64\n",
      " 15  screen_width_mean                      37411 non-null  float64\n",
      " 16  screen_height_mean                     37411 non-null  float64\n",
      " 17  screen_width_median                    37411 non-null  float64\n",
      " 18  screen_height_median                   37411 non-null  float64\n",
      " 19  verify-email-otp                       37411 non-null  float64\n",
      " 20  welcome                                37411 non-null  float64\n",
      " 21  app/applicant/personal-info            37411 non-null  float64\n",
      " 22  app/applicant/phone                    37411 non-null  float64\n",
      " 23  app/applicant/otp-verify               37411 non-null  float64\n",
      " 24  app/applicant/address                  37411 non-null  float64\n",
      " 25  app/applicant/dob-ssn                  37411 non-null  float64\n",
      " 26  app/business/business-type             37411 non-null  float64\n",
      " 27  app/business/address                   37411 non-null  float64\n",
      " 28  app/business/other-info                37411 non-null  float64\n",
      " 29  app/business-questions/about-business  37411 non-null  float64\n",
      " 30  app/business-questions/incoming        37411 non-null  float64\n",
      " 31  page_count                             37411 non-null  float64\n",
      " 32  sh_sw_ratio_count                      37411 non-null  float64\n",
      " 33  sh_sw_ratio_max                        37411 non-null  float64\n",
      " 34  sh_sw_ratio_min                        37411 non-null  float64\n",
      " 35  sh_sw_ratio_mean                       37411 non-null  float64\n",
      " 36  sh_sw_ratio_median                     37411 non-null  float64\n",
      "dtypes: float64(28), int64(8), object(1)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "app_level_data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628c822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_level_data_test.to_pickle(project_path+'data/segment_processed_data_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40ea2e",
   "metadata": {},
   "source": [
    "### OOT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eba854bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_pages_oot = pd.read_pickle(project_path+'data/segment_oot_dataset_2023-05-30.pkl')\n",
    "# Filter only the existing applications in segment data\n",
    "segment_pages_oot = segment_pages_oot[~segment_pages_oot.received_at.isnull()]\n",
    "segment_pages_oot.reset_index(drop=True, inplace=True)\n",
    "segment_pages_oot = segment_pages_oot.sort_values(by=['application_id','received_at'])\n",
    "\n",
    "# Change data type\n",
    "cols = ['application_id','user_id','owner_id','anonymous_id','context_page_path','timezone']\n",
    "segment_pages_oot[cols] = segment_pages_oot[cols].astype('string')\n",
    "segment_pages_oot[['screen_width','screen_height']] = segment_pages_oot[['screen_width','screen_height']].astype('int')\n",
    "\n",
    "for col in segment_pages_oot.columns:\n",
    "    if col != 'user_id':\n",
    "        idx = segment_pages_oot.index[segment_pages_oot[col].isnull()].tolist()\n",
    "        idx.extend(segment_pages_oot.index[segment_pages_oot[col].isna()].tolist())\n",
    "        idx.extend(segment_pages_oot.index[segment_pages_oot[col] == ''].tolist())\n",
    "        idx.extend(segment_pages_oot.index[segment_pages_oot[col] == '[]'].tolist())\n",
    "        idx = list(set(idx))\n",
    "        segment_pages_oot.loc[idx, col] = None    \n",
    "\n",
    "\n",
    "df_oot = pd.read_pickle(project_path+'data/nsl_oot_dataset_2023-05-30.pkl')\n",
    "\n",
    "df_oot_tmp = pd.merge(segment_pages_oot, df_oot[['application_id', 'ns_flag']], on='application_id', how='inner')\n",
    "x_oot = df_oot_tmp.reset_index(drop=True)\n",
    "\n",
    "cols_list = ['timezone','user_id','owner_id','anonymous_id','context_ip','screen_width','screen_height']\n",
    "# Creating df with all apps\n",
    "app_level_data = pd.DataFrame()\n",
    "app_level_data['application_id'] = x_oot.application_id.unique()\n",
    "\n",
    "app_level_data = segment_features_1(df=x_oot, cols_list=cols_list, app_level_df=app_level_data, training=False)\n",
    "app_level_data = segment_features_2(df=x_oot, app_level_df=app_level_data, training=False)\n",
    "\n",
    "df_oot = pd.merge(df_oot[['application_id', 'ns_flag']], app_level_data, on='application_id', how='left')\n",
    "x_oot = df_oot.reset_index(drop=True)\n",
    "y_oot = x_oot['ns_flag']\n",
    "app_level_data_oot = segment_features_3(app_level_df=x_oot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "841ce7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25374, 35)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_level_data_oot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd178788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25374 entries, 0 to 25373\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   application_id                         25374 non-null  object \n",
      " 1   ns_flag                                25374 non-null  int64  \n",
      " 2   timezone_count                         25374 non-null  int64  \n",
      " 3   user_id_count                          25374 non-null  int64  \n",
      " 4   owner_id_count                         25374 non-null  int64  \n",
      " 5   anonymous_id_count                     25374 non-null  int64  \n",
      " 6   context_ip_count                       25374 non-null  int64  \n",
      " 7   screen_width_count                     25374 non-null  int64  \n",
      " 8   screen_height_count                    25374 non-null  int64  \n",
      " 9   screen_width_max                       25374 non-null  float64\n",
      " 10  screen_height_max                      25374 non-null  float64\n",
      " 11  screen_width_min                       25374 non-null  float64\n",
      " 12  screen_height_min                      25374 non-null  float64\n",
      " 13  screen_width_mean                      25374 non-null  float64\n",
      " 14  screen_height_mean                     25374 non-null  float64\n",
      " 15  screen_width_median                    25374 non-null  float64\n",
      " 16  screen_height_median                   25374 non-null  float64\n",
      " 17  verify-email-otp                       25374 non-null  float64\n",
      " 18  welcome                                25374 non-null  float64\n",
      " 19  app/applicant/personal-info            25374 non-null  float64\n",
      " 20  app/applicant/phone                    25374 non-null  float64\n",
      " 21  app/applicant/otp-verify               25374 non-null  float64\n",
      " 22  app/applicant/address                  25374 non-null  float64\n",
      " 23  app/applicant/dob-ssn                  25374 non-null  float64\n",
      " 24  app/business/business-type             25374 non-null  float64\n",
      " 25  app/business/address                   25374 non-null  float64\n",
      " 26  app/business/other-info                25374 non-null  float64\n",
      " 27  app/business-questions/about-business  25374 non-null  float64\n",
      " 28  app/business-questions/incoming        25374 non-null  float64\n",
      " 29  page_count                             25374 non-null  float64\n",
      " 30  sh_sw_ratio_count                      25374 non-null  float64\n",
      " 31  sh_sw_ratio_max                        25374 non-null  float64\n",
      " 32  sh_sw_ratio_min                        25374 non-null  float64\n",
      " 33  sh_sw_ratio_mean                       25374 non-null  float64\n",
      " 34  sh_sw_ratio_median                     25374 non-null  float64\n",
      "dtypes: float64(26), int64(8), object(1)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "app_level_data_oot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0aa1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_level_data_oot.to_pickle(project_path+'data/segment_processed_data_oot.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60131a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f60a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "91ff227bd4746f087dd7a6a642c19acba2eb19bff7f3e32cd1bf0c3801bef747"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
