{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path variables\n",
    "import sys\n",
    "project_path = '/Users/naresh/Downloads/DS/growth/nsl_v2/nsl_v2_final/'\n",
    "\n",
    "# core libraries\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "stop_words = stopwords.words('english')\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124703, 162)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "file = 'nsl_raw_dataset_2023-05-19.pkl'\n",
    "path = project_path + 'data/'\n",
    "df_raw = pd.read_pickle(path + file)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/()]{}\\[\\]\\|@,:!*]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z ]')\n",
    "\n",
    "def cleaning_gen(data):\n",
    "    review = re.sub('[^a-zA-z]',' ',data)\n",
    "    review = review.lower()\n",
    "    review = BAD_SYMBOLS_RE.sub('',review)\n",
    "    review = REPLACE_BY_SPACE_RE.sub(' ', review)\n",
    "    doc = nlp(review)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        tokens.append(token)\n",
    "    tokens = [token.lemma_ for token in doc if token.pos_ in ['VERB','NOUN']]\n",
    "    tokens = [c for c in tokens if c not in stop_words]\n",
    "    tokens = [c for c in tokens if len(c)>1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return (tokens)\n",
    "\n",
    "df_raw['business_pitch_lema_spacy'] = df_raw['business_pitch'].apply(cleaning_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed dataset\n",
    "file = 'nsl_bp_processed_dataset_' + str(datetime.date.today()) + '.pkl'\n",
    "path = project_path + 'data/'\n",
    "df_raw[['application_id', 'business_id', 'business_pitch', 'business_pitch_lema_spacy']].to_pickle(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fa8e7a0e7c7188de72acea4ae1bc222d1770499c4c3d36ce32843ef46b20053"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
